hydra:
  run:
    dir: ${experiment.dir}
  job:
    chdir: False
experiment:
  project_name: PLM-DTI
  experiment_name: davis_dataset
  dir: ${paths.results}/${experiment.project_name}/${experiment.experiment_name}
  verbosity: 3
  seed: 0
  task: davis # "dti_dg" for TDCommons domain generalization benchmark,
            # one of EnzPredDataModule.dataset_list() ("halogenase",
            # "bkace", "gt", "esterase", "kinase", "phosphatase"),
            # "benchmark" for our large DTI benchmark data curation,
            # others - "davis", "bindingdb", "biosnap", "biosnap_prot" (unseen protein),
            # "biosnap_mol" (unseen drug), "dude" (not implemented)
  clearml: false
  only_load_checkpoint_weights: true # if "checkpoint" is provided, specify whether to only load weights (true) or entire training state (lr schedule etc'.) (false)
paths:
  results: '${oc.env:DTI_RESULTS}'

data:
  batch_size: 32
  contrastive_batch_size: 256
  shuffle: True
  num_workers: 16

model:
  # possible values: MorganFeaturizer, others (not tested): Mol2VecFeaturizer, GNN, MolEFeaturizer, MolRFeaturizer
  drug_featurizer: MorganFeaturizer
  # possible values: ProtBertFeaturizer, others (not tested): BeplerBergerFeaturizer, ESMFeaturizer, ProseFeaturizer, ProtT5XLUniref50Featurizer,
  #                  BindPredict21Featurizer, DSCRIPTFeaturizer
  target_featurizer: ProtBertFeaturizer
  # possible values: SimpleCoembedding, others (not tested): GoldmanCPI, SimpleCosine, AffinityCoembedInner, CosineBatchNorm, LSTMCosine, DeepCosine,
  #                  SimpleConcat, SeparateConcat, AffinityEmbedConcat, AffinityConcatLinear
  model_architecture: deepcoembedding
  latent_dimension: 1024
  latent_distance: "Cosine"

trainer:
  loss: 'bce' # 'bce' (binary cross-entropy), 'focal'
  epochs: 50
  every_n_val: 2
  lr: 1e-4
  lr_t0: 10
  contrastive: false # Note: currently not implemented. If true, will be used with DUDE dataset
  contrastive_split: within
  clr: 1e-5
  clr_t0: 10
  device: 0 # 5

test:
  save_preds_for_benchmark_eval: false
# to run test only mode with an already trained model, provide the test.checkpoint argument
# here or via CLI, i.e: python test.py +test.checkpoint=/path/to/checkpoint.ckpt
#  checkpoint: /path/to/checkpoint.ckpt
