paths:
  # tokenizers_path: "_your_path_/modulartokenizer/pretrained_tokenizers/"
  tokenizers_path: "_your_path_/fuse-drug/fusedrug/data/tokenizer/modulartokenizer/pretrained_tokenizers/" #tokenizer base work path
  AA_tokenizer_json: "t5_tokenizer_AA_special.json"
  SMILES_tokenizer_json: "bpe_tokenizer_trained_on_chembl_zinc_with_aug_4272372_samples_balanced_1_1.json"
  modular_tokenizers_out_path: "${paths.tokenizers_path}/modular_AA_SMILES/"
  original_tokenizers_path: "${paths.tokenizers_path}"


hydra:
  run:
    dir: "${paths.modular_tokenizers_out_path}"
    # Please set the BIMCA_RESULTS environment variable to your desired output location.
    # You can override this value when running train.py - for example: python train.py hydra.run.dir='/some/path/you/want'
    # this approach is especially useful when you run a daemonized process which has its stdout/err redirected to a log file within this dir.
    # alternatively, you can use multi-run (looks useful for grid searches etc.)  - read: https://hydra.cc/docs/configure_hydra/workdir/#configuration-for-multirun
    # it uses hydra.sweep.dir and hydra.sweep.subdir (which uses ${hydra.job.num})


data:
  tokenizer:
    # modular_tokenizers_out_path: "${paths.tokenizers_path}/modular_wordlevelAA_BPESMILES/"
    overall_max_len: 70
    max_possible_token_id: 5000
    max_special_token_id: 500
    out_path: "${paths.tokenizers_path}/modular_AA_SMILES_single_path/"
    tokenizers_info:
      - name: AA
        tokenizer_id: 0 #unique int identifier of the tokenizer
        # raw tokenizer json path:
        json_path:         "${paths.original_tokenizers_path}/${paths.AA_tokenizer_json}"
        # updated for use with modular tokenizer json path:
        modular_json_path: "${paths.modular_tokenizers_out_path}/${paths.AA_tokenizer_json}"
        # max_len: 100 # [Optional] max number of tokens to be used by all instances of this tokenizer. If None or undefined, no limit is set.
        start_delimiter: "<start_AA>"
        end_delimiter: "<end_AA>"
      - name: SMILES  #if None or undefined, type key will be used as the name
        tokenizer_id: 1 #unique identifier of the tokenizer
        json_path:         "${paths.original_tokenizers_path}/${paths.SMILES_tokenizer_json}"
        modular_json_path: "${paths.modular_tokenizers_out_path}/${paths.SMILES_tokenizer_json}"
        start_delimiter: "<start_SMILES>" #String to start the sequence. If None or undefined, <start_${type key}> will be used as the name
        end_delimiter: "<end_SMILES>" #String to end the sequence. If None or undefined, <end_${type key}> will be used as the name
